{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook focuses on:\n",
    "- Performing a detailed evaluation of the trained Random Forest model\n",
    "- Understanding model performance using key metrics and visualizations\n",
    "- Performing threshold tuning for optimal recall/precision balance\n",
    "- Generating insights for business decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, recall_score, precision_score, \n",
    "    f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Random Forest model trained in 03_modeling_training.ipynb\n",
    "rf_model = joblib.load(\"../models/churn_random_forest.pkl\")\n",
    "\n",
    "# Load test dataset\n",
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\")\n",
    "\n",
    "# Flatten y_test if necessary\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Verify Test Data\n",
    "- Ensure that the features and target are loaded correctly\n",
    "- Verify shapes to avoid mismatch during prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class labels\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Predict probabilities (needed for ROC & PR curves)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Confusion Matrix\n",
    "Shows the count of true positives, false positives, true negatives, and false negatives\n",
    "python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn','Churn'], yticklabels=['No Churn','Churn'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.savefig(\"../reports/figures/confusion_matrix.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Confusion Matrix – Key Observations\n",
    "- The model correctly identifies **1,412 non-churn customers** and **1,376 churn customers**, indicating strong overall classification performance.\n",
    "- **False Negatives (203 churn customers predicted as non-churn)** represent missed churn risks, which is a critical business concern.\n",
    "- **False Positives (168 non-churn customers predicted as churn)** are comparatively lower and mainly impact retention cost rather than revenue loss.\n",
    "- The model demonstrates a **balanced trade-off between precision and recall**, with a clear emphasis on correctly detecting churn customers.\n",
    "- Overall, the confusion matrix confirms that the model is **well-suited for churn prediction**, effectively capturing churn behavior while maintaining reasonable error levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Classification Report – Key Observations\n",
    "\n",
    "- The model achieves **strong and balanced performance** across both classes, with precision, recall, and F1-scores close to **0.88**.\n",
    "- **Churn recall of 0.87** indicates that the model successfully identifies most churn customers, aligning well with business retention goals.\n",
    "- High precision for both classes (**0.87–0.89**) suggests a low rate of incorrect churn and non-churn predictions.\n",
    "- The close alignment between macro and weighted averages confirms **stable generalization** and minimal class bias.\n",
    "- Overall accuracy of **88%** reinforces the model’s reliability for churn prediction in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 7. ROC Curve and AUC\n",
    "- Measures model's ability to rank positive vs negative cases\n",
    "- Area under curve (AUC) indicates overall discrimination power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f\"Random Forest (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../reports/figures/roc_curve.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### ROC Curve & AUC – Key Observations\n",
    "\n",
    "- The ROC curve shows strong separation from the diagonal baseline, indicating excellent classification performance.\n",
    "- An **AUC of 0.94** confirms the model’s high ability to distinguish between churn and non-churn customers across thresholds.\n",
    "- The curve’s steep rise at low false positive rates demonstrates effective early churn detection.\n",
    "- This strong discriminative power makes the model well-suited for business scenarios where prioritizing churn customers is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 8. Precision-Recall Curve\n",
    "- Useful for imbalanced datasets (like churn)\n",
    "- Shows trade-off between precision and recall for different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recall, precision, color='blue')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "\n",
    "plt.savefig(\"../reports/figures/precision_recall_curve.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Precision–Recall Curve – Key Observations\n",
    "\n",
    "- The curve maintains **high precision across a wide range of recall values**, indicating reliable churn predictions.\n",
    "- Precision remains strong at moderate recall levels, enabling effective targeting of churn customers with minimal false positives.\n",
    "- As recall approaches 1.0, precision declines, reflecting the expected trade-off when attempting to capture all churn cases.\n",
    "- Overall, the curve demonstrates a **well-balanced precision–recall trade-off**, making the model suitable for cost-sensitive churn intervention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 9. Threshold Tuning for Churn Detection\n",
    "- Default threshold is 0.5\n",
    "- We can adjust threshold to capture more churners (increase recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob >= t).astype(int)\n",
    "    recall = recall_score(y_test, y_pred_t)\n",
    "    precision = precision_score(y_test, y_pred_t, zero_division=0)\n",
    "    print(f\"Threshold: {t:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Threshold Tuning – Key Observations\n",
    "\n",
    "- Lower thresholds (≤ 0.30) achieve **near-perfect recall**, ensuring almost all churn customers are identified, but with lower precision.\n",
    "- Increasing the threshold improves precision while gradually reducing recall, highlighting the trade-off between false positives and missed churn cases.\n",
    "- The default threshold (0.50) provides a **strong balance** with high precision (0.89) and recall (0.87).\n",
    "- Very high thresholds (> 0.80) result in no churn predictions, demonstrating why threshold tuning is critical for practical deployment.\n",
    "- Threshold selection should be aligned with business goals, balancing customer retention cost against the risk of missed churners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 10. Feature Importance\n",
    "- Shows which engineered features contribute most to churn prediction\n",
    "- Useful for business insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = joblib.load(\"../models/preprocessor.pkl\")\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_features = feature_importance.head(20)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "plt.title(\"Top 20 Feature Importances - Random Forest\")\n",
    "\n",
    "plt.savefig(\"../reports/figures/feature_importance.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Feature Importance – Key Observations\n",
    "\n",
    "- The top-ranked features contribute disproportionately to the model’s churn predictions, indicating strong predictive signals.\n",
    "- Feature importance drops sharply beyond the top features, suggesting diminishing marginal impact from lower-ranked variables.\n",
    "- The model relies on a combination of behavioral and engineered features rather than a single dominant driver.\n",
    "- These insights can help guide targeted retention strategies and inform future feature selection and model simplification efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 11. Business Insights from Model Evaluation\n",
    "\n",
    "- The Random Forest model demonstrates **strong predictive capability**, achieving high recall and ROC–AUC, making it well-suited for churn detection where missing a churn customer is costly.\n",
    "- High **recall for churn customers** indicates the model can successfully identify most users at risk of leaving, enabling proactive retention strategies.\n",
    "- Threshold tuning allows the business to **balance precision and recall** based on operational priorities:\n",
    "  - Lower thresholds prioritize capturing more churners (useful for early-warning systems)\n",
    "  - Higher thresholds reduce false positives (useful when retention actions are costly)\n",
    "- ROC and Precision–Recall curves confirm the model’s ability to **separate churn and non-churn users across decision thresholds**, indicating robust generalization.\n",
    "- Feature importance analysis provides **actionable insights**, highlighting key behavioral and revenue-related drivers of churn that can inform:\n",
    "  - Targeted retention campaigns\n",
    "  - Product improvements\n",
    "  - Customer engagement strategies\n",
    "- Overall, the model is suitable for **deployment as a decision-support tool**, helping the business reduce churn, optimize retention spend, and improve customer lifetime value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 12. Save Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_csv(\"../data/processed/feature_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 13. Conclusion and Model Selection\n",
    "\n",
    "An end-to-end churn prediction pipeline was implemented, including preprocessing, class imbalance handling, model training, and detailed evaluation. Logistic Regression, Decision Tree, and Random Forest models were compared using business-critical metrics such as recall and ROC–AUC.\n",
    "\n",
    "The **Random Forest model** demonstrated the best overall performance, achieving high churn recall, strong class separation, and stable generalization. Threshold analysis showed that the model can be adjusted to balance recall and precision based on retention strategy. Feature importance analysis added interpretability, enabling actionable business insights rather than black-box predictions.\n",
    "\n",
    "**Final Decision:**  \n",
    "Random Forest is selected as the production-ready model due to its superior ability to identify churn customers while maintaining robust overall performance. The trained model and preprocessing pipeline were saved to ensure reproducibility and deployment readiness.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
