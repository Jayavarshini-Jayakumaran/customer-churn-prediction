{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Model Training & Selection\n",
    "\n",
    "This notebook focuses on:\n",
    "- Training multiple machine learning models on the engineered dataset\n",
    "- Performing basic performance sanity checks\n",
    "- Selecting the best-performing model\n",
    "- Saving the trained model for further evaluation and deployment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/processed_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Dataset Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Ensures correct dimensionality and numeric feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Separate Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['CHURN'])\n",
    "y = df['CHURN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Train–Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Stratification ensures balanced churn distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 6. Baseline Model: Logistic Regression\n",
    "Logistic Regression is used as a baseline linear model to validate preprocessing and establish a reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_prob = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Sanity Metrics (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_pred))\n",
    "print(\"Recall:\", recall_score(y_test, lr_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 7. Decision Tree Model\n",
    "Decision Tree captures non-linear patterns and interactions between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=6,\n",
    "    min_samples_split=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_prob = dt.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Sanity Metrics (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "print(\"Recall:\", recall_score(y_test, dt_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, dt_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 8. Random Forest Model\n",
    "Random Forest is an ensemble model that improves generalization and robustness by combining multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=30,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_prob = rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Sanity Metrics (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"Recall:\", recall_score(y_test, rf_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 9. Model Comparison Summary\n",
    "\n",
    "Three classification models were trained and evaluated to predict customer churn.  \n",
    "Performance was compared using Accuracy, Recall (Churn = 1), and ROC–AUC.\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Accuracy**: Overall correctness of predictions\n",
    "- **Recall (Churn)**: Ability to correctly identify churn customers (business-critical)\n",
    "- **ROC–AUC**: Model’s ability to distinguish churn vs non-churn across thresholds\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| Model               | Accuracy | Recall (Churn) | ROC–AUC |\n",
    "|--------------------|----------|----------------|---------|\n",
    "| Logistic Regression | 0.645    | 0.704          | 0.705   |\n",
    "| Decision Tree       | 0.735    | 0.706          | 0.819   |\n",
    "| Random Forest       | 0.883    | 0.871          | 0.943   |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "- **Logistic Regression** served as a strong baseline, achieving moderate recall and ROC–AUC, validating the effectiveness of preprocessing and feature engineering.\n",
    "- **Decision Tree** improved discriminative power, capturing non-linear patterns and significantly increasing ROC–AUC.\n",
    "- **Random Forest** delivered the best performance across all metrics, with:\n",
    "  - High recall (87%) — effectively identifying most churn customers\n",
    "  - Excellent ROC–AUC (0.94) — strong class separation\n",
    "  - Balanced handling of class imbalance using `class_weight='balanced'`\n",
    "\n",
    "---\n",
    "\n",
    "### Model Selection Decision\n",
    "\n",
    "Given the business objective of minimizing missed churn customers, **Random Forest** was selected as the final model due to its superior recall and overall predictive performance.\n",
    "\n",
    "This model demonstrates strong generalization capability and is well-suited for deployment in churn prediction scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 10. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf, \"../models/churn_random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 11. Save Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"../data/processed/X_test.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "- Multiple models were trained on engineered features\n",
    "- Random Forest showed superior churn detection capability\n",
    "- The trained model has been saved for in-depth evaluation in the next notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
