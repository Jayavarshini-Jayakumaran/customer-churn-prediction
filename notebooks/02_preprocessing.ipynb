{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Customer Churn Prediction\n",
    "\n",
    "This notebook prepares the raw churn dataset for machine learning by:\n",
    "- Cleaning and standardizing data\n",
    "- Handling missing values\n",
    "- Engineering business-driven features\n",
    "- Encoding and scaling variables\n",
    "- Saving a model-ready dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary Python libraries for data manipulation, preprocessing, and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load the Raw Dataset\n",
    "Load the original, unprocessed dataset to ensure reproducibility and a clean pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataset\n",
    "df = pd.read_csv(\"../data/raw/customer_churn_raw.csv\")\n",
    "\n",
    "# Standardize column names for consistency\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# Preview the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Initial Dataset Shape & Sanity Check\n",
    "- Check dataset dimensions\n",
    "- Verify column names and data types\n",
    "- Ensure no unintended changes from the raw file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Drop Identifier and Non-Predictive Columns\n",
    "- Remove unique identifiers such as `PID`\n",
    "- These columns do not add predictive value and may cause data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['PID'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 5.1 Remove High Missing Value Columns\n",
    "- Drop `Suspended_subscribers` due to extremely high missing percentage (~96%)\n",
    "- Such columns add noise and reduce model stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Suspended_subscribers'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 5.2 Impute Logical Zero Values\n",
    "- Impute missing values in `Not_Active_subscribers` with `0`\n",
    "- Missing here likely indicates no inactive subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Not_Active_subscribers'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 5.3 Drop Rows with Negligible Missing Values\n",
    "- Remove rows with missing values in:\n",
    "  - `CRM_PID_Value_Segment`\n",
    "  - `Billing_ZIP`\n",
    "  - `ARPU`\n",
    "- These represent <0.1% of the data and can be safely dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\n",
    "    'CRM_PID_Value_Segment',\n",
    "    'Billing_ZIP',\n",
    "    'ARPU'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 6. Clean & Standardize Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 6.1 Fix Typographical Errors\n",
    "- Correct spelling inconsistencies (e.g., `Sliver` → `Silver`)\n",
    "- Ensures consistent category representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CRM_PID_Value_Segment'] = (\n",
    "    df['CRM_PID_Value_Segment']\n",
    "    .replace({'Sliver': 'Silver'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 6.2 Merge Rare Categories\n",
    "- Combine rare categories into `OtherSegment`\n",
    "- Prevents sparse dummy variables during encoding\n",
    "- Improves model generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_counts = df['CRM_PID_Value_Segment'].value_counts(normalize=True)\n",
    "rare_segments = segment_counts[segment_counts < 0.02].index\n",
    "\n",
    "df['CRM_PID_Value_Segment'] = df['CRM_PID_Value_Segment'].replace(\n",
    "    rare_segments, 'OtherSegment'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 6.3 Ensure Correct Data Types\n",
    "- Convert `Billing_ZIP` to categorical (object) type\n",
    "- ZIP codes represent location, not numeric magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Billing_ZIP'] = df['Billing_ZIP'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 7. Target Variable Encoding\n",
    "- Convert `CHURN` from categorical (`Yes`/`No`) to numeric (`1`/`0`)\n",
    "- Required for machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CHURN'] = df['CHURN'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering\n",
    "Create new features to capture customer behavior, engagement, and revenue patterns more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 8.1 Revenue Intensity per Subscription\n",
    "- Measures how much revenue each subscription generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue_per_Subscription'] = df['TotalRevenue'] / df['Total_SUBs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 8.2 Engagement Score\n",
    "- Ratio of active subscriptions to total subscriptions\n",
    "- Captures customer engagement level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Engagement_Score'] = (\n",
    "    df['Active_subscribers'] / df['Total_SUBs']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 8.3 High Inactive Subscriber Flag\n",
    "- Binary flag indicating presence of inactive subscriptions\n",
    "- Highlights disengaged customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['High_Inactive_Flag'] = np.where(\n",
    "    df['Not_Active_subscribers'] > 0, 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 8.4 Mobile Revenue Contribution Ratio\n",
    "- Measures dependency on mobile services\n",
    "- Useful since mobile revenue dominates overall revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg_Mobile_to_Total_Revenue_Ratio'] = (\n",
    "    df['AvgMobileRevenue'] / df['TotalRevenue']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 8.5 FIX Service Usage Indicator\n",
    "- Binary indicator for FIX (fixed-line) service usage\n",
    "- FIX users showed higher loyalty in EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FIX_User_Flag'] = np.where(df['AvgFIXRevenue'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### 8.6 Multi-Service Customer Flag\n",
    "- Identifies customers using multiple services\n",
    "- Multi-service users tend to churn less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Multi_Service_Flag'] = np.where(\n",
    "    (df['Active_subscribers'] + df['Not_Active_subscribers']) > 1,\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### 8.7 High Revenue Customer Flag\n",
    "- Flags top 10% revenue-generating customers\n",
    "- Important for business risk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_threshold = df['TotalRevenue'].quantile(0.90)\n",
    "df['High_Revenue_Flag'] = np.where(\n",
    "    df['TotalRevenue'] >= revenue_threshold, 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### 8.8 ARPU Category Bucketing\n",
    "- Bucket ARPU into Low / Medium / High\n",
    "- Helps linear models capture non-linear churn patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ARPU_Category'] = pd.qcut(\n",
    "    df['ARPU'], q=3, labels=['Low', 'Medium', 'High']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### 8.9 Customer Revenue Segment\n",
    "- Bucket customers by total revenue\n",
    "- Adds interpretable business-level segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer_Revenue_Segment'] = pd.qcut(\n",
    "    df['TotalRevenue'],\n",
    "    q=4,\n",
    "    labels=['Low', 'Mid', 'High', 'Premium']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### 8.10 Customer Value × Engagement Interaction Feature\n",
    "- Combines revenue intensity and engagement score\n",
    "- Captures high-value but disengaged customers (high churn risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value_Engagement_Index'] = (\n",
    "    df['Revenue_per_Subscription'] * df['Engagement_Score']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### 8.11 Drop Redundant Raw Columns\n",
    "- Remove raw columns now represented by engineered features\n",
    "- Reduces multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\n",
    "    'TotalRevenue',\n",
    "    'AvgMobileRevenue',\n",
    "    'AvgFIXRevenue'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### 8.12 Feature Engineering Summary\n",
    "- Created revenue, engagement, and service-usage based features\n",
    "- Converted business metrics into churn-predictive signals\n",
    "- Removed redundant raw columns to reduce multicollinearity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 9. Separate Features and Target Variable\n",
    "- Split dataset into:\n",
    "  - Feature matrix (X)\n",
    "  - Target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['CHURN'])\n",
    "y = df['CHURN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## 10. Identify Numerical and Categorical Features\n",
    "- Explicitly list numeric and categorical columns\n",
    "- Ensures correct preprocessing steps for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## 11. Feature Scaling and Encoding\n",
    "\n",
    "- Numerical features will be standardized using feature scaling, which is essential for distance-based and linear models. \n",
    "- Categorical variables will be converted into numerical form using One-Hot Encoding, with the first category dropped to avoid the dummy variable trap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder(\n",
    "    drop='first', handle_unknown='ignore'\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## 12. Apply and Save Preprocessing Pipeline\n",
    "\n",
    "- The preprocessing pipeline is applied to the feature set using the defined transformers.\n",
    "- This step performs numerical feature scaling and categorical feature encoding, producing a model-ready feature matrix.\n",
    "- The fitted preprocessing pipeline is saved to ensure consistent transformations during model evaluation and future inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "joblib.dump(preprocessor, \"../models/preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## 13. Handle Class Imbalance with SMOTE\n",
    "\n",
    "- Customer churn datasets are typically **class-imbalanced**, which can bias models toward predicting non-churn users  \n",
    "- **SMOTE (Synthetic Minority Over-sampling Technique)** is applied to balance churn and non-churn classes  \n",
    "- This enables the model to **learn churn patterns more effectively** and improves **recall for churn customers**  \n",
    "- The resampled feature matrix is converted back into a **DataFrame with interpretable feature names** for analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_processed, y)\n",
    "\n",
    "# Convert sparse matrix to dense (for analysis & saving)\n",
    "X_resampled_dense = X_resampled.toarray()\n",
    "\n",
    "# Restore feature names after preprocessing\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Create final processed DataFrame\n",
    "processed_df = pd.DataFrame(X_resampled_dense, columns=feature_names)\n",
    "processed_df['CHURN'] = y_resampled.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## 14. Final Data Quality & Leakage Check\n",
    "- Confirm:\n",
    "  - No missing values remain\n",
    "  - Target variable is not leaked into features\n",
    "  - Dataset shape is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape, y_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## 15. Save the Engineered Dataset\n",
    "- Save the fully processed dataset for modeling\n",
    "- Ensures reproducibility and clean separation of stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting sparse matrix → dense array BEFORE DataFrame\n",
    "X_dense = X_resampled.toarray()\n",
    "\n",
    "processed_df = pd.DataFrame(X_dense)\n",
    "processed_df['CHURN'] = y_resampled.values\n",
    "\n",
    "# Saving\n",
    "processed_df.to_csv(\n",
    "    \"processed_churn_data.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## Final Output\n",
    "- Dataset is fully cleaned, engineered, balanced, and model-ready\n",
    "- Ready for training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
